---
layout: post
title: (위성Segment) [위성사진, SAR] 데이터 찾기 - MSTAR, Codalab
description: >  
    
---
원본 글 위치 :  https://junha1125.tistory.com/53?category=836123


### ****

# **1. Git : MSTAR-tensorflow (star : 28)**

**Git** 사이트에 의하면, [https://github.com/hamza-latif/MSTAR_tensorflow] 다음과 같은 Instruction이 있었다.

> We want to train a deep neural network to identify targets in the three class MSTAR dataset obtained from 
> \1. [https://www.sdms.afrl.af.mil/index.php?collection=mstar&page=targets]
>  and possibly the ten class dataset from 
> \2. [https://www.sdms.afrl.af.mil/index.php?collection=mstar&page=mixed]

이 사이트를 참고하여, Mstar에서 재공하는 public data를 찾아보았다.

Original Website -> [https://www.sdms.afrl.af.mil/index.php] 이 사이트에 회원가입하고(국민대 계정 메일 확인) Download링크를 찾아가면, 그림2의 사이트로 들어갔다. (위 인용구 2개의 사이트 둘 다 그림2로 갔다.)



![img](https://k.kakaocdn.net/dn/JyU0L/btqC6kN7ZzW/BPqY5h1vXvKh2TIciqlKoK/img.png)

![img](https://k.kakaocdn.net/dn/RlOnG/btqC3pJQco8/edlMXJa7go8O0u9sNJAmlk/img.png)그림2



그리고 targets와 mixed와 가장 관련이 깊은 다음의 파일을 다운받아 보았다. 



![img](https://k.kakaocdn.net/dn/bTMvKC/btqC6QlLv3k/x1IAJ9RKyP3Qlr1FWiskcK/img.png)



**1-1 ReadMe 정리**

**- Abstract**

SAR (Synthetic Aperture Radar) 객체 인식은 군사 응용 분야에서 자동 표적 인식 및 공중 정찰에 중요한 문제입니다. SAR 이미지에서 유용한 Feature를 extract하고, classification하기 위해 deep CNN을 사용할 것이다. 데이터 셋은 공개적으로 사용 가능한 MSTAR(Moving and Stationary Target Acquisition and Recognition)을 사용할 것이다.

**- Introduction (DataSet)**

three class MSTAR dataset : [[targets](https://www.sdms.afrl.af.mil/index.php?collection=mstar&page=targets)]

ten class MSTAR dataset : [[mixed](https://www.sdms.afrl.af.mil/index.php?collection=mstar&page=mixed)]

Paper : Deep convolutional neural networks for ATR from SAR imagery [Morgan 2015] [[링크](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9475/94750F/Deep-convolutional-neural-networks-for-ATR-from-SAR-imagery/10.1117/12.2176558.short?SSO=1)]

ten class 문제에 대해서 92.3%의 분류 정확도를 기록했다.

**- Background**

SAR (Synthetic Aperture Radar)은 거리에 걸쳐 안테나의 움직임을 사용하여 큰 "합성"안테나 조리개를 만들어 표준 레이더보다 훨씬 더 정밀한 해상도 이미지를 제공하는 레이더의 한 형태입니다. [[기본 원리](https://www.geo.uzh.ch/~fpaul/sar_theory.html)]



![img](https://k.kakaocdn.net/dn/bZ1lzG/btqC771Fpkc/euygrwU87th1DbKhVRxugk/img.png)



MSTAR 데이터 세트는 1995-1997 년에 수집 된 SAR 이미지 모음이다.

이미지는 SAR 이미지는 128 x 128 픽셀이며, float 형태의 객체 크기(magnitude) 및 위상(phase) 데이터를 포함합니다. 우리의 목적을 위해 크기(magnitude) 데이터 만 고려한다.

**- Network 구조** 

가장 Base구조로 ResNet을 사용한다. 총 32개의 layer로 되어 있으며, Shape 변화는 이와 같다.

input size = 1(?)*128*128 -> 64*32*32 ->(average pooling) 64 ->(FC) -> 10 

 

#### **2. \**Git :\** mstar-bin-tool  (star : 99)**

#### **3. \**Git :\** yi-hack-MStar (star : 150****)**

-> (예상) 2개의 Git은 MSTAR 데이터를 해석하고 읽어주는 tool에 대한 firmware를 다루는 코드인 듯 하다.

우리가 원하는, 데이터 셋을 찾고 전처리하고 그리고 예측 신경망을 만들어 classification을 하는 것은 없는 듯 하다.

 

PS. 

MSTAR dataset 다루는 방법에 관한 글 (나중에 더 찾아볼 것) : [[링크](https://www.researchgate.net/post/Format_of_SAR_images_in_MSTAR_public_dataset_is_of_type_004_001_etc_How_can_I_use_these_images_for_training_my_SAR_ATR_system)]

위 글의 [답변](https://www.sdms.afrl.af.mil/index.php?collection=tools_mstar)에 따르면 이 MSTAR에서 제공하는 툴을 이용하면 된다고 한다.

우선 툴이 있다는 정도만 알아두기... 

 

 

# **<위성 데이터, SAR 데이터, 유용한 것 찾아보기>**

### **[CodaLab]**

과거에 신청해놓았던, 대회들을 통해서, 코드와 dataset을 찾아보았다. 



![img](https://k.kakaocdn.net/dn/cKcG3M/btqC8GQ0FGp/Y8eKvkCK4RsLovVMwmsKkk/img.png)



<1. DeepGlobe Land Cover Classification Challenge>

\- the challenge of automatic classification of land cover types.

\- a multi-class segmentation task to detect areas

\- of urban, agriculture, rangeland, forest, water, barren, and unknown.

 

Participate -> Get Data에서 데이터들 설명 -> Files에서 파일을 다운받을 수 있다. 



![img](https://k.kakaocdn.net/dn/kxAaw/btqC9ydU798/i5lQEboiHOKiCGn9ofxcl0/img.png)

