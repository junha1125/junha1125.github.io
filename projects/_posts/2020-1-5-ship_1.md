---
layout: post
title: 【선박분류】 프로젝트 위한 Docker/DLPC 환경설정하기
description: >  
    DLPC는 국민대 딥러닝 서버 이름입니다. 
---
(선박분류) 프로젝트 위한 Docker/DLPC 환경설정하기

## 사이트 목록

DLPC : [https://dlpc.cs.kookmin.ac.kr/](https://dlpc.cs.kookmin.ac.kr/jobs/297/user/20151128/lab)

Project : Dacon 

BaseLine Code :[ https://github.com/SIAnalytics/simplified_rbox_cnn](https://github.com/SIAnalytics/simplified_rbox_cnn)



![img](https://k.kakaocdn.net/dn/duwzPc/btqCaRUSTQg/Sa7Jr7MWkwbmLLLI1LGNr1/img.png)


------

### **[Docker 환경설정]**

Local환경에서 baseline Code를 돌리기 위해 다음과 같은 환경설정을 하였다.

우선 아래의 이미지가 baseline code를 돌리는데 문제가 없다고 하여, 도커이미지를 다운 받았다.

 

Docker Hub TF Repo: https://hub.docker.com/r/tensorflow/tensorflow

TF 1.6 py3-gpu Docker Image: https://hub.docker.com/layers/tensorflow/tensorflow/1.6.0-gpu-py3/images/sha256-0f4b997bc3af4caa3b700552bf295dde3a6a36c4816ff036d0ddd1632e73cb52

> $docker pull tensorflow/tensorflow:1.6.0-gpu-py3

 

그리고 이를 실행하기 위해 다음과 같은 코드로 실행시켰다.

> $ sudo docker run --runtime=nvidia -it [--rm] -p 8888:8888 -p 6006:6006 --name tf16 tensorflow/tensorflow:1.6.0-gpu-py3

실행하면 자동으로 주피터가 열린다. 주피터 환경에서 upload를 진행했다. upload는 baseline의 git repository를 전체 git clone한 것을 압축하여 업로드 하였다. 파일이 주피터에 올라갔으면 터미널에서 아래의 명령어를 사용해 압축을 풀었다. ([압축 하기, 풀기](https://realforce111.tistory.com/40))

> $ tar -xvzf <simpli~~>.tar

 

ctrl+c를 통해서 서버를 닫은 다음, 다음을 순차적으로 실행하면 정상적으로 동작하는 것을 확인하였다.

> $ docker start <containerID>
> $ docker attach <containerID>
> chrome 의 주소창에 -> http://localhost:8888/tree

그러면 이전에 넣었던 파일이 그대로 있고, 주피터 환경이 열리는 것을 알 수있다.

그리고 이 파일을 내 도커 허브에 올려놓기 위해 다음의 명령어를 사용했다.

 

> docker commit <e36a9 ContainerID> <tf16_with_rboc/ImageName/tag는 자동으로 latest>

도커 허브에 올리기

> $ docker login
> $ export DOCKER_ID_USER="sb020518" # str변수 정의 해둠
> $ docker tag tf16_with_rboc:latest $DOCKER_ID_USER/tf16_with_rbox
> $ docker push $DOCKER_ID_USER/tf16_with_rbox

 

------

### **[DLPC 환경설정]**

DLPC에서 baseline Code를 돌리기 위한 준비를 다음과 같이 환경설정 하였다.

 

**1. virtualenv를 설치하기**

패키지와 라이브러리들을 잘 관리하기 위해 virtualenv를 사용한다. 

anaconda를 사용하려고 했지만, anaconda는 docker에서 좀 더 아래 Layer여서 사용할 수가 없었다. 또는 docker inside docker 방법으로 내가 활동하는 docker위에 docker를 새로 설치함으로써 내가 위에서 만든 이미지를 다운받아 사용하려고 하였다. 

https://gist.github.com/Geoyi/d9fab4f609e9f75941946be45000632b

> $ sudo pip3 install virtualenv
> $ virtualenv venv
> $ source ./venv/bin/activate

 

 

**2. google drive handling**

연결 끊김 방지 :  https://bryan7.tistory.com/1077function ClickConnect() { var buttons = document.querySelectorAll("[colab-dialog.yes-no-dialog](https://junha1125.tistory.com/colab-dialog.yes-no-dialog) paper-button#cancel");  buttons.forEach(function(btn) { [btn.click();](https://junha1125.tistory.com/btn.click();) });  [console.log(](https://junha1125.tistory.com/console.log()"1분마다 자동 재연결");  document.querySelector("#top-toolbar > colab-connect-button").click(); } setInterval(ClickConnect,1000*60); function CleanCurrentOutput(){var btn = document.querySelector(".output-icon.clear_outputs_enabled.output-icon-selected[title$='현재 실행 중...'] iron-icon[command=clear-focused-or-selected-outputs]");if(btn) { console.log("30분마다 출력 지우기"); btn.click(); } }setInterval(CleanCurrentOutput,1000*60*30);

colab : Alpha_project.ipynb

> from google.colab import drive
> drive.mount('/content/gdrive')
> % cd /content/gdrive/My Drive/알파돌고래/10th
> ! ls

 

**3. 추가 패키지 다운받기**

baseline code : https://github.com/SIAnalytics/simplified_rbox_cnn

tenserflow object detection API : https://github.com/tensorflow/models/tree/master/research/object_detection

API install : https://github.com/tensorflow/models/tree/master/research/object_detection

 

> 
> $ pip install --ignore-installed --upgrade tensorflow-gpu==1.6.0
> $ pip install OpenCV-Python==3.4.9.31 
> **아래코드) DLPC에서 이것이 uninstall 되는 경우가 잦으므로, 자주 다시 설치해주기**
> $ sudo apt-get install protobuf-compiler python-pil python-lxml python-tk  
>
> $ pip install Cython contextlib2 pillow lxml jupyter matplotlib
> $ pip list                  #venv에서 activate 하고 있을때. 

 

**4. baseline 코드 실행해보기**

> $ cd ~/Rbox_junha/simplified_rbox_cnn/
> $ protoc protos/*.proto --python_out=.

 

**5. Data Set 다운로드**

 

\1. dropbox계정에 로그인을 한다.

\2. 제공된 Data Set이 저장되어 있는 dropbox에서, send to my directory를 선택하여, 나의 계정에 파일을 넣어놓는다. 

\3. share link를 만들어 링크를 복사한다.

(ex) https://www.dropbox.com/s/ja<file ID>uf/0~400%28with_json%29.zip?dl=0)

\4. DLPC에서 다음과 같이 명령어를 친다. 

@ 주의 : sudo mv 0~400\(with_json\).zip\?dl\=0 다음과 같이 특수문자를 사용하기 위해 [\과 같이 사용](https://superuser.com/questions/1280432/im-getting-a-bash-syntax-error-near-unexpected-token)해야 한다.

> $ sudo wget [https://www.dropbox.com](https://www.dropbox.com/)/s/jauf/0~400%28with_json%29.zip?dl=0 
> \# 다운 받은 파일의 이름을 바꾼다.
> $ sudo mv 0~400\(with_json\).zip\?dl\=0 0~400\(with_json\).zip
> \# 그리고 다음과 같이 압축을 해제한다. 
> $ sudo unzip 0~400\(with_json\).zip -d ./0~400         # [해당파일을 압축해제](https://poppy-leni.tistory.com/entry/Linux-zip-압축-압축풀기). 0_400이라는 폴더 내부에 사진 저장.

\5. 그 다음 파일을 다운받기 위해, send to my directory 또 실행하면 공간부족이라고 뜬다. 따라서, 이전 파일을 지우고 1번~5번까지의 과정을 다시 반복한다.



![img](https://k.kakaocdn.net/dn/oufsk/btqCgReQCF3/dGKt55yKfttt4lXYbWdow1/img.png)



 

 

 

**6. train을 위한 Data Set 만들기**

아래와 같은 명령어를 사용해서, 어떤 폴더에 있는 모든 사진(파일)들을 다른 폴더로 옮긴다. 

> $ sudo  mv  ./0~400/*  ./0~400+json/

**7. create_dataset (TFRecord 생성하기)**



![img](https://k.kakaocdn.net/dn/cubG9C/btqChGxjuoM/AOeY4zDXTAuvDUcg7fD2A1/img.png)



**8. config 설정하기**



![img](https://k.kakaocdn.net/dn/BIAsw/btqCimZHKjG/0DDNVJI7KndOnja30Ny9gK/img.png)



**9. train하기**

python train.py ...

 

 

**10. python train_n_eval.sh**



![img](https://k.kakaocdn.net/dn/bPryab/btqCinEixQn/7fX24ublJnxVeHWJcm5TIk/img.png)



------

## 실행 순서

1. pip install --ignore-installed --upgrade tensorflow==1.6.0 

2.  [https://dacon.io/competitions/official/235492/codeshare/615]
3. pip install shapely
4.  sudo python3 [create_dataset.py](https://junha1125.tistory.com/create_dataset.py) --src_dir='train' --dst_path='train.tfrecord' --is_include_only_pos

6. sudo python3 [train.py](https://junha1125.tistory.com/train.py) --pipeline_config_path="configs/[rbox_cnn_resnet101.config](https://junha1125.tistory.com/rbox_cnn_resnet101.config)" --train_dir="train"

