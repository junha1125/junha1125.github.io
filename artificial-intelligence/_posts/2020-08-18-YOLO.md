---
layout: post
title: 【Paper】 YOLO (You Only Live Once) V1 V2 V3 핵심정리
description: >
     One Stage Detector의 시작이라고 할 수 있는 Yolo, SSD에 대해서 다시 공부하고 정리해본다.
---

[YOLO (You Only Live Once)](https://pjreddie.com/darknet/yolo/)

# 1. Yolo의 이해

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91861910-4c7ad280-eca8-11ea-9b4f-2fab4b4afdcc.png' alt='drawing' width='400'/></p>

- V3의 초록에서 COCO dataset에 대해서 0.5 IOU를 기준으로 하면 RetinaNet보다 성능도 좋고 빠르다고 변명하고 있다.
- RetinaNet의 장점 - 작은 Object에 대해서도 Bounding Box Object Detection을 잘 수행한 한다는 것을 할 수 있다.  
- Version에 따른 특징
     - Version1 : 빠른 Detection 시간. 그러나 낮은 정확도. 그 뒤 SSD가 더 좋은 성능과 속도
     - Version2 : 수행시간과 성능 모두 개선. SSD보다 빠르지만 성능은 아주 조금 개선
     - Version3 : 수행시간은 조금 느려졌으나 성능은 대폭 개선

# 2. YOLO Version 1
- 학습 절차
     1. 어떤 입력 이미지 크기든 상관없이, 이미지를 S x S Grid Cell(7 x 7)로 나눈다. 
     2. 하나의 Cell이 하나의 Object에 대한 Detection을 수행한다. 
     3. 각 Grid Cell이 2개의 Bounding Box 후보를 기반으로 Object의 Bounding Box를 예측한다. (Anchor Box 기반은 아니다. Cell이 그냥 2개의 Box를 추측하는 것이 전부이다.)

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91864107-d2981880-ecaa-11ea-80f4-55a491e4d10f.png' alt='drawing' width='700'/></p>

- 위 이미지 설명
     - S x S x (B x 5 + C) : S x S = 7 x 7 , B = bounding box + Confidence Score , C = Class 갯수
     - Confidence Score : (Object 인지, 아닌지에 대한 확률) x (Grid Cell에 대한 Bounding Box와 GT Box와의 IOU값) 이 나오도록 학습되는 값이다. 
     - bounding box  : x, y, w, h 는 Grid Cell에 대한 예측되 나와야 하는 Bounding Box 좌표값이다. ㄴ
     - 20개의 Class에 대한 Softmax값이 나오도록 학습되는 값이다. Bounding Box가 2개인데 (20개 Class)x2 인 40개가 있는게 아니고 20개만 있다. 그 이유는 한 Grid Cell에 대해서 한 Object만 Detect하겠다는 의지를 담고 있다. (Yolo V1의 단점이라고 할 수 있다. Version2에서 바뀐다.)

<p align="center"><img src='https://user-images.githubusercontent.com/46951365/91865812-bd23ee00-ecac-11ea-8252-6c639d9457d5.png' alt='drawing' width='500'/></p>
 
- 위 이미지 설명
     - 위위 이미지의 흐름을 통해서 첫번째 보라색 박스의 결과가 추출 된다. 
     - 가운데 위 : 7 x 7 x 2 개의 bounding box에 대한 offset값과, Confidence 값
     - 가운데 아래 : Class에 대한 20개 Softmax값에 대해, 가장 큰 확률값을 가지는 Object probability 값.
     - NMS 과정을 거쳐, 오른쪽 최종 결과를 추출한다. ([NMS 과정 정리 이전 게시물](https://junha1125.github.io/artificial-intelligence/2020-08-10-detect,segmenta/#4-object-detection-%ED%95%84%EC%88%98-%EA%B5%AC%EC%84%B1-%EC%84%B1%EB%B6%84))  
          \<NMS 과정>
          1. 높은 confidence를 가지는 Bbox를 정렬
          2. 높은 Confidence Score의 Box부터 겹치는 다른 Box를 모두 조사하여 특정 IOU 이상인 Box를 모두 제거 한다(IOU Threshold > 0.4, [주의] 이 값이 낮을 수록 많은 Box가 제거 된다. )
          3. 위의 과정을 반복해서 최종적으로 남은 Box만 return 한다. 

- YOLO v1 문제점
     - Detection 시간은 빠르나 성능은 떨어짐. 특히 작은 물체에 대한 성능 나쁨.
     - Anchor Box를 사용하지 않으므로, 어떤 힌트가 없다. Cell에 대해서 Bounding Box를 단순 예측 한다. 
     - Anchor Box라는 힌트를 사용하지 않으므로, Bounding box가 생성되는 패턴이 들쭉날쭉해서 예측 오류가 많다. 
     - 하나의 Cell에서 하나의 Object만 예측하므로, 겹친 Object는 Detect하지 못한다. 

# 3. YOLO Version 2
     

글 정리중 .. 곧 업데이트 될 예정 입니다!!
{:.lead}