---
layout: post
title: 【Detection】FCOS - Fully Convolutional One-Stage Object Detection
---

- **논문** : [FCOS: Fully Convolutional One-Stage Object Detection](https://arxiv.org/pdf/1904.01355.pdf)
- **분류** : Object Detection
- **저자** : Zhi Tian Chunhua Shen∗ Hao Chen Tong He
- **읽는 배경** : 교수님 수업의 Programming Assignment 대비하기
- **느낀점 :** 
  - 
- **목차**
  1. Paper Review
  2. Code Review
     - Github link : [https://github.com/tianzhi0549/FCOS](https://github.com/tianzhi0549/FCOS)



# FCOS

# 1. Conclusion, Abstract, Introduction

1. anchor boxes와 관련된 hyper-parameter와 학습 중 Matching 및 IOU 계산에 대한 연산들을 모두 제거했다. Hyper-parametor를 제거함으로써 heuristics한 many trick들을 모두 없앴다. 그리고 Anchor와의 관계 연산을 하지 않으므로 Faster Training이 가능하다.
2. Sementic Segmentation 처럼. per-pixel prediction fashion 을 수행한다. 
3. two-stage Detector에서 RPN으로 사용해도 좋은 결과를 가져왔다. RPN 또한 Anchor-based 이다.
4. NMS 를 사용한 후처리 과정은 필요하다. FCOS with ResNeXt-64x4d-101에서 SOTA 성능 44.7% AP를 획득했다. 우리 모델은 simple and fast 하다!
5. 원래 Class confidence만 예측하는 head만 있으면, low-quality predicted bounding boxes 들이 너무 많이 생긴다. 그래서 우리는 해당 1x1 pixel 점이 객체의 center와 얼마나 떨어져있냐를 수치로 가지고 있는 center-ness 값이 추출되도록 head를 추가했다. 



---

# 2. Our Approach

![image-20210306155338457](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210306155338457.png)

## 3.1 Fully Convolutional One-Stage Object Detector

- 우선 전체 architecture와 필기 꼭 참고하기. 그리고 아래의 수식들 하나하나 읽기.

![image-20210306160218840](C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210306160218840.png)



## 3.2. Multi-level Prediction with FPN for FCOS

- FPN을 사용해서 Recall을 증가시키고, Overlapped bounding box의 ambiguity (다중 객체가 겹치는 해당 Feature map pixel에서 어떤 BB를 예측할 것인가?) 를 해결했다. 
- FPN으로 적용되는 stride값은 P3, P4, P5, P6 and P7 에 대해서, 각각  8, 16, 32, 64 and 128 이다. 이 값은 위의 S 로 동작한다. 
- Anchor-based detector에서 각각의 P_l 은 자신만의 Anchor size를 가짐으로써, 각 Level에서 검출하는 Instance의 크기가 서로 다른다. 여기서도 이런 개념을 추가했다. the range of bounding box regression 를 할당했다. 그 과정은 이와 같다. 
  - (1) 우선 모든 Feature level에 t* ( l* , t* , r* , b* ) 를 연산해놓는다. (Image에 대응하는 (l, t, r, b)를 S로 나눠주면 된다.) 
  - (2) 만약 max( l* , t* , r* , b* ) > m_i or max( l* , t* , r* , b* )< m_(i−1) 즉 일정 범위를 벗어나면 negative sample이라고 파악하고,  bounding box regression 학습에 사용하지 않는다. 
  - (3) 여기서 m2, m3, m4, m5, m6 and m7 는 각각 0, 64, 128, 256, 512 and ∞ 으로 설정해 사용했다. 
  - 이 과정을 통해서, Inference을 하는 동안에는 각각의 Pyramid Feature level들은 자신이 예측해야하는 적절한 크기의 Instance를 우선적으로 검출한다. 
- (필기참조) 하나의 Feature level Picel이 1개 이상의 GT BB를 할당하고 있다면, 단순하게 더 작은 area를 가진 GT BB를 Ground True로 설정해 예측하도록 한다. 
- 그리고 단순하게 Shared Heads Between Feature Levels 를 사용한다. 즉 위의 보라색 head는 모두 파라메터를 공유한다. parameter-efficient (파라메터가 효율적으로 적은) 모델을 만들고 성능도 높혀준다. 하지만 이런 작업이 각 Level이 찾으려고 하는 Instance의 크기가 다른 것을 고려할 때 그리 합리적인 방법은 아닐 수 있습니다. 
- (필기참조) 그래서 우리는 그냥 exp(x)를 사용하는 것 대신에, exp(s_i \* x) 를 사용했다. (s_i 는  trainable scalar) 알아서 각 Level에 필요한 s_i 값을 주어줄 것이라고 예측했다. 



## 3.3. Center-ness for FCOS

- (위 그림 참조) 그냥 Class Score만을 사용해서 NMS를 적용하니, a lot of low-quality predicted bounding boxes 가 추출되는 것을 확인할 수 있었다. 그래서 Center-ness를 예측하는 branch를 새롭게 만들었다. 
- 그 branch에서는 normalized distance를 의미하는“center-ness”를 예측한다.     
  <img src="C:\Users\sb020\AppData\Roaming\Typora\typora-user-images\image-20210307163927443.png" alt="image-20210307163927443" style="zoom:70%;" />
- When testing, 위의 Architecture 그림 처럼, center-ness와 classification score를 곱해서 최종 Confidence로 사용한다. 그리고 NMS를 적용한다.
- the center-ness를 사용하는 것 대신에, central portion (FSAF에서 Efficient Region (GT instance BB의 0.2 공간))을 사용하는 방법도 있다. 하지만 이것 조차 extra hyper-parameter를 사용하는 방법이라는 것에 명심해야한다. 
- [FCOS_PLUS](https://github.com/yqyao/FCOS_PLUS) 에서는 위의 2가지 방법을 융합해서 성능을 높혔다고 한다.

