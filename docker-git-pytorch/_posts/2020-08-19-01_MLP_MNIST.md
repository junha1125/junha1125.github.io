---
layout: post
title: 【Pytorch 실습】Mnist 데이터셋 2층 MLP로 학습 및 추론  
description: > 
      Mnist 데이터 셋을 다운받고 pytorch를 사용해서 학습 및 추론을 합니다. 아래의 코드는 Kaggle 및 Git의 공개된 코드를 적극 활용했습니다. 
---

train, test 파일 다운받는 경로 :  
[https://www.kaggle.com/oddrationale/mnist-in-csv](https://www.kaggle.com/oddrationale/mnist-in-csv)  
{:.lead} PS. jupyter 실행결과도 코드 박스로 출력되어 있습니다.

## 1. 데이터 로드하기

```python
# Load Dataset
import pandas as pd
train_dataset = pd.read_csv("./mnist_train.csv")
test_dataset = pd.read_csv("./mnist_test.csv")
```

```python
# Check Train Set
train_dataset.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>1x1</th>
      <th>1x2</th>
      <th>1x3</th>
      <th>1x4</th>
      <th>1x5</th>
      <th>1x6</th>
      <th>1x7</th>
      <th>1x8</th>
      <th>1x9</th>
      <th>...</th>
      <th>28x19</th>
      <th>28x20</th>
      <th>28x21</th>
      <th>28x22</th>
      <th>28x23</th>
      <th>28x24</th>
      <th>28x25</th>
      <th>28x26</th>
      <th>28x27</th>
      <th>28x28</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 785 columns</p>
</div>

```python
# Check Test Set
test_dataset.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>1x1</th>
      <th>1x2</th>
      <th>1x3</th>
      <th>1x4</th>
      <th>1x5</th>
      <th>1x6</th>
      <th>1x7</th>
      <th>1x8</th>
      <th>1x9</th>
      <th>...</th>
      <th>28x19</th>
      <th>28x20</th>
      <th>28x21</th>
      <th>28x22</th>
      <th>28x23</th>
      <th>28x24</th>
      <th>28x25</th>
      <th>28x26</th>
      <th>28x27</th>
      <th>28x28</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 785 columns</p>
</div>

```python
# Split to Image & Label
train_images = (train_dataset.iloc[:, 1:].values).astype("float32")
train_labels = train_dataset["label"].values
test_images = (test_dataset.iloc[:, 1:].values).astype("float32")
```

```python
# Check Train Data's Image
print(train_images)
```

    [[0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     ...
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]]

```python
# Check Train Data's Label
print(train_labels)
```

    [5 0 4 ... 5 6 8]

```python
# Check Test Data's Image
test_images
```

    array([[0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           ...,
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)

```python
# Split into Train, Valid Dataset 분리 비율은 8:2
from sklearn.model_selection import train_test_split
train_images, valid_images, train_labels, valid_labels = train_test_split(train_images,
                                                                          train_labels,
                                                                          stratify = train_labels,
                                                                          random_state = 42,
                                                                          test_size = 0.2)
```

```python
# Check Train, Valid, Test Image's Shape
print("The Shape of Train Images: ", train_images.shape)
print("The Shape of Valid Images: ", valid_images.shape)
print("The Shape of Test Images: ", test_images.shape)
```

    The Shape of Train Images:  (48000, 784)
    The Shape of Valid Images:  (12000, 784)
    The Shape of Test Images:  (10000, 784)

```python
# Check Train, Valid Label's Shape
print("The Shape of Train Labels: ", train_labels.shape)
print("The Shape of Valid Labels: ", valid_labels.shape)
```

    The Shape of Train Labels:  (38400,)
    The Shape of Valid Labels:  (9600,)

```python
# Reshape image's size to check for ours
train_images = train_images.reshape(train_images.shape[0], 28, 28)
valid_images = valid_images.reshape(valid_images.shape[0], 28, 28)
test_images = test_images.reshape(test_images.shape[0], 28, 28)
```

    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-18-f37841568d28> in <module>
          2 train_images = train_images.reshape(train_images.shape[0], 28, 28)
          3 valid_images = valid_images.reshape(valid_images.shape[0], 28, 28)
    ----> 4 test_images = test_images.reshape(test_images.shape[0], 28, 28)


    ValueError: cannot reshape array of size 7850000 into shape (10000,28,28)

```python
# Check Train, Valid, Test Image's Shape after reshape
print("The Shape of Train Images: ", train_images.shape)
print("The Shape of Valid Images: ", valid_images.shape)
print("The Shape of Test Images: ", test_images.shape)
```

    The Shape of Train Images:  (38400, 28, 28)
    The Shape of Valid Images:  (9600, 28, 28)
    The Shape of Test Images:  (10000, 785)

```python
# Visualize Train, Valid, Test's Images
import matplotlib.pyplot as plt
for idx in range(0, 5):
    plt.imshow(train_images[idx], cmap = plt.get_cmap('gray'))
    plt.title(train_labels[idx])
    plt.show()
```

![svg](01_MLP_MNIST_files/01_MLP_MNIST_13_0.svg)

![svg](01_MLP_MNIST_files/01_MLP_MNIST_13_1.svg)

![svg](01_MLP_MNIST_files/01_MLP_MNIST_13_2.svg)

![svg](01_MLP_MNIST_files/01_MLP_MNIST_13_3.svg)

![svg](01_MLP_MNIST_files/01_MLP_MNIST_13_4.svg)

```python
for idx in range(0, 5):
    plt.imshow(valid_images[idx], cmap = plt.get_cmap('gray'))
    plt.title(valid_labels[idx])
    plt.show()
```

![png](01_MLP_MNIST_files/01_MLP_MNIST_14_0.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_14_1.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_14_2.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_14_3.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_14_4.png)

```python
for idx in range(0, 5):
    plt.imshow(test_images[idx], cmap = plt.get_cmap('gray'))
    plt.show()
```

![png](01_MLP_MNIST_files/01_MLP_MNIST_15_0.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_15_1.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_15_2.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_15_3.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_15_4.png)

## 2. Torch를 이용한 데이터 로드, 모델 생성

지금까지 로드한 데이터를 torch.tensor형태로 데이터를 변환해준다.

```python
# Make Dataloader to feed on Multi Layer Perceptron Model
# train과 test 셋을 batch 단위로 데이터를 처리하기 위해서. _loader를 정의 해준다.
import torch
from torch.utils.data import TensorDataset, DataLoader
train_images_tensor = torch.tensor(train_images)
train_labels_tensor = torch.tensor(train_labels)
train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)
train_loader = DataLoader(train_tensor, batch_size = 64, num_workers = 0, shuffle = True)

valid_images_tensor = torch.tensor(valid_images)
valid_labels_tensor = torch.tensor(valid_labels)
valid_tensor = TensorDataset(valid_images_tensor, valid_labels_tensor)
valid_loader = DataLoader(valid_tensor, batch_size = 64, num_workers = 0, shuffle = True)

test_images_tensor = torch.tensor(test_images)
```

```python
# Create Multi Layer Perceptron Model
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.input_layer = nn.Linear(28 * 28, 128)
        self.hidden_layer = nn.Linear(128, 128)
        self.output_layer = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = F.relu(self.input_layer(x))
        x = F.relu(self.hidden_layer(x))
        x = self.output_layer(x)
        x = F.log_softmax(x, dim = 1)
        return x

USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")

model = MLP().to(DEVICE)
optimizer = optim.Adam(model.parameters(), lr = 0.001)  # optimization 함수 설정

print("Model: ", model)
print("Device: ", DEVICE)
```

    Model:  MLP(
      (input_layer): Linear(in_features=784, out_features=128, bias=True)
      (hidden_layer): Linear(in_features=128, out_features=128, bias=True)
      (output_layer): Linear(in_features=128, out_features=10, bias=True)
    )
    Device:  cpu

## 3. 여기까지 모델 설계. 이제 학습 시작

```python
# Definite Train & Evaluate
# 이제 학습키자!
def train(model, train_loader, optimizer):
    model.train()  # "나 모델을 이용해서 학습시킬게! 라는 의미"
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)
        optimizer.zero_grad()
        output = model(data)
        loss = F.cross_entropy(output, target)  # criterion
        loss.backward()
        optimizer.step()

        if batch_idx % 100 == 0:
            print("Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}".format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))

def evaluate(model, valid_loader):
    model.eval()  # "나 모델을 이용해서 학습시킬게! 라는 의미"
    valid_loss = 0  # just Loss를 확인하기 위해서.
    correct = 0

    with torch.no_grad():
        for data, target in valid_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            output = model(data)
            valid_loss += F.cross_entropy(output, target, reduction = "sum").item()
            prediction = output.max(1, keepdim = True)[1]
            correct += prediction.eq(target.view_as(prediction)).sum().item()

    valid_loss /= len(valid_loader.dataset)
    valid_accuracy = 100. * correct / len(valid_loader.dataset)
    return valid_loss, valid_accuracy
```

```python
''' Training'''
EPOCHS = 10
for epoch in range(1, EPOCHS + 1):
    train(model, train_loader, optimizer)
    valid_loss, valid_accuracy = evaluate(model, valid_loader)
    print("[EPOCH: {}], \tValidation Loss: {:.4f}, \tValidation Accuracy: {:.2f} %\n".format(epoch, valid_loss, valid_accuracy))
```

    Train Epoch: 1 [0/38400 (0%)]	Loss: 7.859256
    Train Epoch: 1 [6400/38400 (17%)]	Loss: 0.257251
    Train Epoch: 1 [12800/38400 (33%)]	Loss: 0.397648
    Train Epoch: 1 [19200/38400 (50%)]	Loss: 0.124491
    Train Epoch: 1 [25600/38400 (67%)]	Loss: 0.369470
    Train Epoch: 1 [32000/38400 (83%)]	Loss: 0.102254
    [EPOCH: 1], 	Validation Loss: 0.2195, 	Validation Accuracy: 93.82 %

    Train Epoch: 2 [0/38400 (0%)]	Loss: 0.055376
    Train Epoch: 2 [6400/38400 (17%)]	Loss: 0.147356
    Train Epoch: 2 [12800/38400 (33%)]	Loss: 0.088759
    Train Epoch: 2 [19200/38400 (50%)]	Loss: 0.310786
    Train Epoch: 2 [25600/38400 (67%)]	Loss: 0.070934
    Train Epoch: 2 [32000/38400 (83%)]	Loss: 0.197948
    [EPOCH: 2], 	Validation Loss: 0.1787, 	Validation Accuracy: 94.98 %

    Train Epoch: 3 [0/38400 (0%)]	Loss: 0.047470
    Train Epoch: 3 [6400/38400 (17%)]	Loss: 0.040136
    Train Epoch: 3 [12800/38400 (33%)]	Loss: 0.069432
    Train Epoch: 3 [19200/38400 (50%)]	Loss: 0.096422
    Train Epoch: 3 [25600/38400 (67%)]	Loss: 0.286610
    Train Epoch: 3 [32000/38400 (83%)]	Loss: 0.212956
    [EPOCH: 3], 	Validation Loss: 0.1721, 	Validation Accuracy: 95.53 %

    Train Epoch: 4 [0/38400 (0%)]	Loss: 0.017488
    Train Epoch: 4 [6400/38400 (17%)]	Loss: 0.042994
    Train Epoch: 4 [12800/38400 (33%)]	Loss: 0.054302
    Train Epoch: 4 [19200/38400 (50%)]	Loss: 0.061861
    Train Epoch: 4 [25600/38400 (67%)]	Loss: 0.066437
    Train Epoch: 4 [32000/38400 (83%)]	Loss: 0.181618
    [EPOCH: 4], 	Validation Loss: 0.1655, 	Validation Accuracy: 95.93 %

    Train Epoch: 5 [0/38400 (0%)]	Loss: 0.157900
    Train Epoch: 5 [6400/38400 (17%)]	Loss: 0.022676
    Train Epoch: 5 [12800/38400 (33%)]	Loss: 0.079706
    Train Epoch: 5 [19200/38400 (50%)]	Loss: 0.011348
    Train Epoch: 5 [25600/38400 (67%)]	Loss: 0.224695
    Train Epoch: 5 [32000/38400 (83%)]	Loss: 0.161174
    [EPOCH: 5], 	Validation Loss: 0.1998, 	Validation Accuracy: 95.36 %

    Train Epoch: 6 [0/38400 (0%)]	Loss: 0.170737
    Train Epoch: 6 [6400/38400 (17%)]	Loss: 0.054293
    Train Epoch: 6 [12800/38400 (33%)]	Loss: 0.221803
    Train Epoch: 6 [19200/38400 (50%)]	Loss: 0.047757
    Train Epoch: 6 [25600/38400 (67%)]	Loss: 0.068296
    Train Epoch: 6 [32000/38400 (83%)]	Loss: 0.091958
    [EPOCH: 6], 	Validation Loss: 0.1611, 	Validation Accuracy: 96.38 %

    Train Epoch: 7 [0/38400 (0%)]	Loss: 0.152233
    Train Epoch: 7 [6400/38400 (17%)]	Loss: 0.002884
    Train Epoch: 7 [12800/38400 (33%)]	Loss: 0.132517
    Train Epoch: 7 [19200/38400 (50%)]	Loss: 0.099287
    Train Epoch: 7 [25600/38400 (67%)]	Loss: 0.040992
    Train Epoch: 7 [32000/38400 (83%)]	Loss: 0.212544
    [EPOCH: 7], 	Validation Loss: 0.2104, 	Validation Accuracy: 95.43 %

    Train Epoch: 8 [0/38400 (0%)]	Loss: 0.055127
    Train Epoch: 8 [6400/38400 (17%)]	Loss: 0.065782
    Train Epoch: 8 [12800/38400 (33%)]	Loss: 0.046110
    Train Epoch: 8 [19200/38400 (50%)]	Loss: 0.207948
    Train Epoch: 8 [25600/38400 (67%)]	Loss: 0.091346
    Train Epoch: 8 [32000/38400 (83%)]	Loss: 0.034671
    [EPOCH: 8], 	Validation Loss: 0.1639, 	Validation Accuracy: 96.47 %

    Train Epoch: 9 [0/38400 (0%)]	Loss: 0.005890
    Train Epoch: 9 [6400/38400 (17%)]	Loss: 0.054453
    Train Epoch: 9 [12800/38400 (33%)]	Loss: 0.017136
    Train Epoch: 9 [19200/38400 (50%)]	Loss: 0.004437
    Train Epoch: 9 [25600/38400 (67%)]	Loss: 0.150551
    Train Epoch: 9 [32000/38400 (83%)]	Loss: 0.177758
    [EPOCH: 9], 	Validation Loss: 0.2030, 	Validation Accuracy: 95.92 %

    Train Epoch: 10 [0/38400 (0%)]	Loss: 0.075817
    Train Epoch: 10 [6400/38400 (17%)]	Loss: 0.075776
    Train Epoch: 10 [12800/38400 (33%)]	Loss: 0.010031
    Train Epoch: 10 [19200/38400 (50%)]	Loss: 0.056201
    Train Epoch: 10 [25600/38400 (67%)]	Loss: 0.056001
    Train Epoch: 10 [32000/38400 (83%)]	Loss: 0.103519
    [EPOCH: 10], 	Validation Loss: 0.2131, 	Validation Accuracy: 95.54 %

## 4. Test 하고 Test 결과를 출력해보자.

```python
# Predict Test Dataset
# Validation 과 Test 같은 경우에 다음과 같이 torch.no_grad를 꼭 사용하니 참고하자.
def testset_prediction(model, test_images_tensor):
    model.eval()  # test모드 아니고, validation모드를 사용한다.
    result = []
    with torch.no_grad():
        for data in test_images_tensor:
            data = data.to(DEVICE)
            output = model(data)
            prediction = output.max(1, keepdim = True)[1]
            result.append(prediction.tolist())
    return result
```

```python
test_predict_result = testset_prediction(model, test_images_tensor)
test_predict_result[:5]
```

    [[[7]], [[2]], [[1]], [[0]], [[4]]]

```python
import numpy as np
from collections import Counter
Counter(np.squeeze(test_predict_result)).most_common()
```

    [(1, 1139),
     (3, 1115),
     (9, 1113),
     (7, 991),
     (0, 979),
     (8, 959),
     (6, 949),
     (4, 938),
     (2, 934),
     (5, 883)]

```python
for idx in range(0, 10):
    plt.imshow(test_images[idx], cmap = plt.get_cmap('gray'))
    plt.title("Predict: " + str(test_predict_result[idx]))
    plt.show()
```

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_0.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_1.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_2.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_3.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_4.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_5.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_6.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_7.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_8.png)

![png](01_MLP_MNIST_files/01_MLP_MNIST_26_9.png)

```python

```
